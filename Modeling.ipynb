{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _________________________________________ \r\n",
      "/ K: Cobalt's metal, hard and shining;    \\\r\n",
      "|                                         |\r\n",
      "| Cobol's wordy and confining;            |\r\n",
      "|                                         |\r\n",
      "| KOBOLDS topple when you strike them;    |\r\n",
      "|                                         |\r\n",
      "| Don't feel bad, it's hard to like them. |\r\n",
      "|                                         |\r\n",
      "\\ -- The Roguelet's ABC                   /\r\n",
      " ----------------------------------------- \r\n",
      "      \\                    / \\  //\\\r\n",
      "       \\    |\\___/|      /   \\//  \\\\\r\n",
      "            /0  0  \\__  /    //  | \\ \\    \r\n",
      "           /     /  \\/_/    //   |  \\  \\  \r\n",
      "           @_^_@'/   \\/_   //    |   \\   \\ \r\n",
      "           //_^_/     \\/_ //     |    \\    \\\r\n",
      "        ( //) |        \\///      |     \\     \\\r\n",
      "      ( / /) _|_ /   )  //       |      \\     _\\\r\n",
      "    ( // /) '/,_ _ _/  ( ; -.    |    _ _\\.-~        .-~~~^-.\r\n",
      "  (( / / )) ,-{        _      `-.|.-~-.           .~         `.\r\n",
      " (( // / ))  '/\\      /                 ~-. _ .-~      .-~^-.  \\\r\n",
      " (( /// ))      `.   {            }                   /      \\  \\\r\n",
      "  (( / ))     .----~-.\\        \\-'                 .~         \\  `. \\^-.\r\n",
      "             ///.----..>        \\             _ -~             `.  ^-`  ^-_\r\n",
      "               ///-._ _ _ _ _ _ _}^ - - - - ~                     ~-- ,.-~\r\n",
      "                                                                  /.-~\r\n"
     ]
    }
   ],
   "source": [
    "# %load src/header.py\n",
    "'''LOAD'''\n",
    "# %load /Users/rokushou/Desktop/header.py\n",
    "'''GENERAL'''\n",
    "import os\n",
    "#import time\n",
    "#import timeit\n",
    "#import warnings\n",
    "#warnings.simplefilter('ignore')\n",
    "import random\n",
    "import collections\n",
    "#import secrets\n",
    "import math\n",
    "import itertools\n",
    "'''DATA'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import databricks.koalas as ks\n",
    "'''MONGO'''\n",
    "#from pymongo import MongoClient\n",
    "'''PLOT'''\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-pastel')\n",
    "font = {'size':16}\n",
    "import seaborn as sns\n",
    "'''SCIPY/STATS'''\n",
    "#import scipy.stats as scs\n",
    "# from scipy.optimize import nnls\n",
    "#import statsmodels.api as sm\n",
    "'''SCIKIT LEARN'''\n",
    "#from sklearn.datasets import make_classification, load_iris, load_boston, load_digits\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit, cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, r2_score, mean_squared_error, classification_report, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier, AdaBoostRegressor, AdaBoostClassifier\n",
    "# from sklearn.decomposition import PCA, NMF\n",
    "# from sklearn.cluster import KMeans\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "'''TENSORFLOW'''\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from tensorflow.keras import utils\n",
    "'''NLTK'''\n",
    "#import nltk\n",
    "#import unicodedata\n",
    "#import string\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "#from nltk.stem.wordnet import WordNetLemmatizer\n",
    "'''NETWORK'''\n",
    "# import networkx as nx\n",
    "# import nxpd\n",
    "# import community as comm\n",
    "'''FUNCTIONS'''\n",
    "nrange = lambda x : itertools.repeat(None, x)\n",
    "def argpsort(a, k):\n",
    "    return np.argpartition(a, range(k))[:k]\n",
    "def arghsort(a, k):\n",
    "    b = np.argpartition(a, k)[:k]\n",
    "    return b[np.argsort(a[b])]\n",
    "'''PALETTE'''\n",
    "t = 'setsuna'\n",
    "qan = {'setsuna':'quanta'}\n",
    "twi = '#DCB8E7' #Pale, light grayish mulberry\n",
    "twi_blu = '#273873' #Dark sapphire blue\n",
    "twi_pur = '#662D8A' #Moderate purple\n",
    "twi_pnk = '#ED438D' #Brilliant raspberry\n",
    "'''RETURN'''\n",
    "!fortune | cowsay -f dragon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "First I load in my cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12769497 entries, 0 to 15623\n",
      "Data columns (total 10 columns):\n",
      "match         int64\n",
      "game-ver      object\n",
      "lobby-mode    object\n",
      "lobby         object\n",
      "mode          object\n",
      "stage         object\n",
      "weapon        object\n",
      "rank          object\n",
      "level         float64\n",
      "win           bool\n",
      "dtypes: bool(1), float64(1), int64(1), object(7)\n",
      "memory usage: 986.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('data/clean.pkl')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is much more data than I need and very slow to work with so I will select only the most recent (based on game version) and work with that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4.2.0', '4.3.0', '4.3.1', '3.0.0', '1.3.0', '3.0.1', '4.4.0',\n",
       "       '4.5.0', '4.5.1', '4.6.0', '4.6.1', '4.7.0', '2.2.2', '1.4.2',\n",
       "       '2.0.0', '3.1.0', '3.2.0', '4.8.0', '3.2.1', '3.2.2', '1.1.2',\n",
       "       '4.0.0', '4.1.0', '2.3.3', '2.3.2', '1.4.0', '2.2.1', '2.1.0',\n",
       "       '2.1.1', '2.3.1', '1.4.1', '1.2.0', '2.2.0', '2.0.1', '2.3.0',\n",
       "       '1.0.0'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['game-ver'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396655, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['game-ver']=='4.8.0']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40k is still plenty and I may decide to random sample from it if my models are stil taking too long. The features I am most intersted in are mode, weapon, and rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yagura', 'asari', 'area', 'nawabari', 'hoko'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['s', 'a', 'a+', 'a-', nan, 'x', 's+', 'c-', 'b-', 'b', 'c+', 'b+',\n",
       "       'c'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ochiba', 'dynamo_tesla', 'sshooter_becchu', 'wakaba',\n",
       "       'jetsweeper', 'clashblaster_neo', 'prime_becchu',\n",
       "       'maneuver_collabo', 'jetsweeper_custom', 'nzap89',\n",
       "       'sputtery_clear', 'sharp_neo', 'dualsweeper_custom', 'bold_7',\n",
       "       'momiji', 'carbon_deco', 'splatroller', 'spygadget_becchu',\n",
       "       'hokusai_hue', 'maneuver', '52gal', 'hotblaster', 'furo',\n",
       "       'sputtery_hue', 'bold', 'variableroller_foil', 'longblaster',\n",
       "       'pablo', 'sshooter_collabo', 'hydra_custom', 'nzap85',\n",
       "       'screwslosher', 'explosher', 'l3reelgun_d', 'pablo_hue',\n",
       "       'prime_collabo', 'promodeler_pg', 'spygadget', 'nzap83',\n",
       "       'sputtery', 'kelvin525_deco', 'liter4k_scope_custom',\n",
       "       'hokusai_becchu', 'kugelschreiber_hue', 'screwslosher_neo',\n",
       "       'maneuver_becchu', 'splatscope', 'promodeler_mg', 'bold_neo',\n",
       "       'barrelspinner_remix', 'herospinner_replica', 'nautilus47',\n",
       "       'h3reelgun_d', 'dualsweeper', 'liter4k_custom',\n",
       "       'hotblaster_custom', 'nova', 'bamboo14mk1', 'heroroller_replica',\n",
       "       'splatcharger', 'heroshelter_replica', 'longblaster_necro',\n",
       "       'squiclean_b', 'sshooter', 'dynamo_becchu', 'rapid_becchu',\n",
       "       'kelvin525', '52gal_becchu', 'bucketslosher_deco',\n",
       "       'splatroller_becchu', 'carbon', 'barrelspinner',\n",
       "       'heroshooter_replica', 'rapid', 'soytuber_custom', 'nova_neo',\n",
       "       'kugelschreiber', 'promodeler_rg', 'hissen_hue',\n",
       "       'screwslosher_becchu', 'squiclean_g', 'splatspinner_collabo',\n",
       "       'prime', '96gal', 'splatroller_collabo', 'quadhopper_black',\n",
       "       'bucketslosher', 'dynamo', 'splatscope_collabo', 'pablo_permanent',\n",
       "       'splatspinner', 'splatcharger_becchu', 'liter4k', 'furo_deco',\n",
       "       'octoshooter_replica', 'splatspinner_becchu', 'parashelter',\n",
       "       'explosher_custom', 'campingshelter', 'splatcharger_collabo',\n",
       "       'l3reelgun', 'herocharger_replica', 'nautilus79', 'nova_becchu',\n",
       "       'squiclean_a', 'rapid_elite', '96gal_deco', 'rapid_elite_deco',\n",
       "       'campingshelter_camo', 'sharp', 'h3reelgun_cherry', 'hydra',\n",
       "       'heromaneuver_replica', 'splatscope_becchu', 'liter4k_scope',\n",
       "       'parashelter_sorella', 'bamboo14mk2', 'quadhopper_white',\n",
       "       'l3reelgun_becchu', 'rapid_deco', 'hokusai', 'clashblaster',\n",
       "       'heroblaster_replica', '52gal_deco', 'bottlegeyser_foil',\n",
       "       'barrelspinner_deco', 'h3reelgun', 'variableroller', 'bamboo14mk3',\n",
       "       'heroslosher_replica', 'spygadget_sorella',\n",
       "       'campingshelter_sorella', 'bucketslosher_soda', 'soytuber',\n",
       "       'kelvin525_becchu', 'bottlegeyser', 'hissen', 'longblaster_custom',\n",
       "       'herobrush_replica'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weapon'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break the dataframe into features and labels, then get dummies for the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['lobby', 'mode', 'stage', 'weapon', 'rank', 'level']]\n",
    "y = df.win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396655, 186)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That created a lot of features but I have enough observations. Next to create a basic test train split and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.517399176451714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5197903695271855"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5175443287470302"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5110277546467833"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "sgd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df[['lobby', 'mode', 'stage', 'weapon', 'rank', 'level']])\n",
    "y = df.win\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 239182 samples, validate on 26576 samples\n",
      "Epoch 1/10\n",
      "239182/239182 [==============================] - 3s 13us/sample - loss: 0.7378 - accuracy: 0.5005 - val_loss: 0.6959 - val_accuracy: 0.5035\n",
      "Epoch 2/10\n",
      "239182/239182 [==============================] - 2s 10us/sample - loss: 0.6944 - accuracy: 0.5095 - val_loss: 0.6931 - val_accuracy: 0.5058\n",
      "Epoch 3/10\n",
      "239182/239182 [==============================] - 3s 11us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6926 - val_accuracy: 0.5062\n",
      "Epoch 4/10\n",
      "239182/239182 [==============================] - 3s 11us/sample - loss: 0.6915 - accuracy: 0.5213 - val_loss: 0.6928 - val_accuracy: 0.5062\n",
      "Epoch 5/10\n",
      "239182/239182 [==============================] - 3s 11us/sample - loss: 0.6918 - accuracy: 0.5198 - val_loss: 0.6937 - val_accuracy: 0.5160\n",
      "Epoch 6/10\n",
      "239182/239182 [==============================] - 2s 10us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6933 - val_accuracy: 0.5166\n",
      "Epoch 7/10\n",
      "239182/239182 [==============================] - 3s 11us/sample - loss: 0.6911 - accuracy: 0.5223 - val_loss: 0.6925 - val_accuracy: 0.5148\n",
      "Epoch 8/10\n",
      "239182/239182 [==============================] - 3s 11us/sample - loss: 0.6916 - accuracy: 0.5221 - val_loss: 0.6928 - val_accuracy: 0.5096\n",
      "Epoch 9/10\n",
      "239182/239182 [==============================] - 2s 10us/sample - loss: 0.6910 - accuracy: 0.5230 - val_loss: 0.6929 - val_accuracy: 0.5096\n",
      "Epoch 10/10\n",
      "239182/239182 [==============================] - 2s 9us/sample - loss: 0.6916 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3e580e10>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=50, input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=4000, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35997, 30097],\n",
       "       [32923, 31880]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, model.predict_classes(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
